{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/AUTOMATIC1111/stable-diffusion-webui"
      ],
      "metadata": {
        "id": "gfKvWAVnz8OB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Colab was created by user: daswer123**\n",
        "\n",
        "https://github.com/daswer123/stable-diffusion-colab\n",
        "\n",
        "**If you liked the colab, give it a star :)**"
      ],
      "metadata": {
        "id": "WbSBMNZnmPt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Update python to 3.9\n",
        "!wget -O mini.sh https://repo.anaconda.com/miniconda/Miniconda3-py38_4.8.2-Linux-x86_64.sh\n",
        "!chmod +x mini.sh\n",
        "!bash ./mini.sh -b -f -p /usr/local\n",
        "!conda install -q -y jupyter\n",
        "!conda install -q -y google-colab -c conda-forge\n",
        "!python -m ipykernel install --name \"py39\" --user\n",
        "\n",
        "%cd /content/\n",
        "#@title #Simple start webui stable diffusion by voldemort!\n",
        "\n",
        "#@markdown Full loading of all components takes about 5-6 minutes\n",
        "\n",
        "#@markdown ##Dowload model:\n",
        "Model = \"nai\" #@param [\"Stable-diffusion 1.4\",\"nai\",\"waifu-diffusion 1.2\", \"waifu-diffusion 1.3 release\"]\n",
        "\n",
        "#@markdown ##Gdrive:\n",
        "#@markdown #####If you select gdrive, the model will not be downloaded, but copied from your drive\n",
        "mount_gdrive = False #@param{type:\"boolean\"}\n",
        "#@markdown #####Write the folder or theass as path to the folder, you can leave the field blank if the model is in the root of the drive\n",
        "gdrive_path = \"model.ckpt\" #@param {type:\"string\"}\n",
        "#@markdown Your path look like /content/drive/MyDrive/**gdrive_path**\n",
        "\n",
        "#@markdown ##Extra\n",
        "download_hypernetworks_modules = True #@param{type:\"boolean\"}\n",
        "#@markdown Make result same as nai \n",
        "special_config_for_nai = True #@param{type:\"boolean\"}\n",
        "#@markdown ##### If you do not want to load the model from google disk, but want to connect it for example to display pictures, then select this checkbox\n",
        "mount_gdrive_for_outputs = False #@param{type:\"boolean\"}\n",
        "#@markdown #####There is a bug in which the output of the image can cause lag and they will not be displayed, for this instead of running gradio uses localltunel, which allows to fix this bug\n",
        "Use_localtunnel = False #@param{type:\"boolean\"}\n",
        "\n",
        "import time\n",
        "\n",
        "if mount_gdrive == True or mount_gdrive_for_outputs == True:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "!nvidia-smi\n",
        "!ls /usr/share/fonts/truetype/\n",
        "!npm install -g localtunnel\n",
        "!pip install tensorflow\n",
        "!pip install tensorflow_io\n",
        "!pip install gdown\n",
        "!pip install git+https://github.com/KichangKim/DeepDanbooru.git@edf73df4cdaeea2cf00e9ac08bd8a9026b7a7b26\n",
        "!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
        "%cd /content/stable-diffusion-webui\n",
        "# !git reset --hard c30c06db207a580d76544fd10fc1e03cd58ce85e\n",
        "# !pip install -r requirements.txt\n",
        "# !mkdir repositories\n",
        "# !git clone https://github.com/CompVis/stable-diffusion.git repositories/stable-diffusion\n",
        "# !git clone https://github.com/CompVis/taming-transformers.git repositories/taming-transformers\n",
        "# !git clone https://github.com/sczhou/CodeFormer.git repositories/CodeFormer\n",
        "# !git clone https://github.com/salesforce/BLIP.git repositories/BLIP\n",
        "# !pip install -r repositories/CodeFormer/requirements.txt\n",
        "# !git clone https://github.com/crowsonkb/k-diffusion repositories/k-diffusion\n",
        "# !pip install clip\n",
        "\n",
        "\n",
        "\n",
        "%cd /content/stable-diffusion-webui\n",
        "if mount_gdrive == True:\n",
        "    new_gdrive_path = \"/content/drive/MyDrive/\" + gdrive_path\n",
        "    !cp $new_gdrive_path /content/stable-diffusion-webui/models/model.ckpt\n",
        "else:\n",
        "    if(Model == \"Stable-diffusion 1.4\"):\n",
        "      user_header = f\"\\\"Authorization: Bearer {'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'}\\\"\"\n",
        "      !wget --header={user_header} https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt -O model.ckpt\n",
        "    elif(Model == \"waifu-diffusion 1.2\"):\n",
        "        !wget \"http://wd.links.sd:8880/wd-v1-2-full-ema.ckpt\" -O /content/stable-diffusion-webui/model.ckpt\n",
        "    elif(Model == \"waifu-diffusion 1.3 release\"):\n",
        "        !gdown https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float32.ckpt -O /content/stable-diffusion-webui/model.ckpt\n",
        "    elif(Model == \"nai\"):\n",
        "        !gdown https://huggingface.co/Daswer123/asdasdadsa/resolve/main/novelai_full.ckpt -O /content/stable-diffusion-webui/models/Stable-diffusion/nai.ckpt\n",
        "        !gdown https://huggingface.co/Daswer123/asdasdadsa/resolve/main/animevae.pt -O /content/stable-diffusion-webui/models/Stable-diffusion/nai.vae.pt\n",
        "        !gdown https://huggingface.co/Daswer123/asdasdadsa/raw/main/nai.yaml -O /content/stable-diffusion-webui/models/Stable-diffusion/nai.yaml\n",
        "        !gdown https://huggingface.co/Daswer123/asdasdadsa/resolve/main/v2.pt -O /content/stable-diffusion-webui/v2.pt\n",
        "        !gdown https://huggingface.co/Daswer123/asdasdadsa/raw/main/v2enable.py -O /content/stable-diffusion-webui/scripts/v2enable.py\n",
        "    else:\n",
        "        !gdown https://drive.google.com/uc?id=1EdZmlteF8EThBu9Rpf2JMRFSLbVD7EXa -O /content/stable-diffusion-webui/model.ckpt\n",
        "\n",
        "if(download_hypernetworks_modules == True):\n",
        "  %cd /content/stable-diffusion-webui/models/\n",
        "  !gdown https://huggingface.co/Daswer123/asdasdadsa/resolve/main/hypernetworks.zip -O /content/stable-diffusion-webui/models/hypernetworks.zip \n",
        "  !unzip /content/stable-diffusion-webui/models/hypernetworks.zip \n",
        "\n",
        "#Mini-scrtipt to change one line in code\n",
        "%cd /content/stable-diffusion-webui\n",
        "def replace_line(file_name, line_num, text):\n",
        "    lines = open(file_name, 'r').readlines()\n",
        "    lines[line_num] = text\n",
        "    out = open(file_name, 'w')\n",
        "    out.writelines(lines)\n",
        "    out.close()\n",
        "\n",
        "def replace_line_in_file(file_name, line_to_search, text_to_replace):\n",
        "    with open(file_name, 'r') as file:\n",
        "        # read a list of lines into data\n",
        "        data = file.readlines()\n",
        "\n",
        "    for line in data:\n",
        "        # if the line contains the string we're looking for,\n",
        "        # write the line to the output file\n",
        "        if line_to_search in line:\n",
        "            replace_line(file_name, data.index(line), text_to_replace)\n",
        "\n",
        "%cd /content/stable-diffusion-webui/modules\n",
        "replace_line_in_file('sd_models.py', 'pl_sd = torch.load(checkpoint_file, map_location=\"cpu\")', '    pl_sd = torch.load(checkpoint_file, map_location=\"cuda:0\")\\n')\n",
        "%cd /content/stable-diffusion-webui\n",
        "\n",
        "if(special_config_for_nai == True):\n",
        "   !wget https://pastebin.com/raw/ukEFznTb -O /content/stable-diffusion-webui/ui-config.json\n",
        "\n",
        "\n",
        "time.sleep(1)\n",
        "%cd /content/stable-diffusion-webui\n",
        "if (Use_localtunnel == True):\n",
        "  !nohup lt -p 7860 > lt.log 2>&1 &  \n",
        "  time.sleep(1)\n",
        "  with open('/content/stable-diffusion-webui/lt.log', 'r') as testwritefile:\n",
        "    print(\"\\033[92m\" + \"Wait for the model to load and follow this link\")\n",
        "    print(testwritefile.read())\n",
        "    print(\"\\033[95m\")\n",
        "  !python launch.py --deepdanbooru\n",
        "else:\n",
        "  !python launch.py --share --deepdanbooru"
      ],
      "metadata": {
        "id": "SSP9suJcjlWs",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#If something get wrong\n",
        "So that you don't have to restart the colab, you can quickly do it here"
      ],
      "metadata": {
        "id": "BLt0o9_XMEgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Simple Restarting\n",
        "#@markdown ###Do you want to use/leave the localtunnel?:\n",
        "%cd /content/stable-diffusion-webui\n",
        "Use_Localtunnel = False #@param{type:\"boolean\"}\n",
        "\n",
        "if Use_Localtunnel == True:\n",
        "  !nohup lt -p 7860 > lt.log 2>&1 &  \n",
        "  time.sleep(2)\n",
        "  with open('/content/stable-diffusion-webui/lt.log', 'r') as testwritefile:\n",
        "    print(\"\\033[92m\" + \"Wait for the model to load and follow this link\")\n",
        "    print(testwritefile.read())\n",
        "    print(\"\\033[95m\")\n",
        "  !python launch.py --deepdanbooru\n",
        "else:\n",
        "  !python launch.py --share --deepdanbooru"
      ],
      "metadata": {
        "id": "qPXSMTXPMOkq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}